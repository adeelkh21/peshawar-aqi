name: AQI Model Training Pipeline

on:
  schedule:
    # Run every 6 hours (at 00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 */6 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches: [ main ]
    paths:
      - '.github/workflows/aqi_model_training.yml'

permissions:
  contents: write
  pull-requests: write

jobs:
  train-model:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        lfs: true
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create model directories
      run: |
        mkdir -p data_repositories/models
        mkdir -p data_repositories/models/trained_models
        mkdir -p data_repositories/models/evaluation_reports
        mkdir -p deployment/
        
    - name: Verify training data availability
      run: |
        python -c "
        import os, sys, logging
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        # Check for available training data sources
        data_sources = [
            'data_repositories/processed/merged_data.csv',
            'data_repositories/historical_data/real_historical_dataset.csv',
            'data_repositories/historical_data/150_days_baseline.csv'
        ]
        
        available_sources = []
        for source in data_sources:
            if os.path.exists(source):
                available_sources.append(source)
                logger.info(f'✅ Found data source: {source}')
        
        if not available_sources:
            logger.error('❌ No training data sources found. Please ensure data collection pipeline has run.')
            sys.exit(1)
        
        logger.info(f'📊 Found {len(available_sources)} data source(s) for training')
        "
        
    - name: Prepare training dataset
      run: |
        python -c "
        import sys
        sys.path.append('.')
        import pandas as pd
        import os
        from datetime import datetime, timedelta
        import logging
        
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        logger.info('🔄 Preparing training dataset...')
        
        try:
            # Priority order for data sources
            data_sources = [
                'data_repositories/processed/merged_data.csv',  # Latest preserved data
                'data_repositories/historical_data/real_historical_dataset.csv',  # Real historical
                'data_repositories/historical_data/150_days_baseline.csv'  # Baseline historical
            ]
            
            training_df = None
            source_used = None
            
            # Find the best available data source
            for source in data_sources:
                if os.path.exists(source):
                    try:
                        df = pd.read_csv(source)
                        if len(df) > 0 and 'timestamp' in df.columns:
                            training_df = df
                            source_used = source
                            logger.info(f'📦 Using data source: {source}')
                            logger.info(f'📊 Records: {len(df):,}')
                            break
                    except Exception as e:
                        logger.warning(f'⚠️ Could not read {source}: {e}')
                        continue
            
            if training_df is None:
                logger.error('❌ No valid training data source found')
                sys.exit(1)
            
            # Validate and prepare data
            training_df['timestamp'] = pd.to_datetime(training_df['timestamp'])
            training_df = training_df.sort_values('timestamp').reset_index(drop=True)
            
            # Remove any incomplete recent data (last hour)
            if len(training_df) > 0:
                latest_ts = training_df['timestamp'].max()
                cutoff_time = latest_ts - timedelta(hours=1)
                training_df = training_df[training_df['timestamp'] <= cutoff_time]
                logger.info(f'🧹 Trimmed to {len(training_df):,} records (removed incomplete recent data)')
            
            # Save prepared training dataset
            training_file = 'data_repositories/processed/complete_training_dataset.csv'
            training_df.to_csv(training_file, index=False)
            
            logger.info(f'✅ Training dataset prepared: {len(training_df):,} records')
            logger.info(f'📅 Date range: {training_df[\"timestamp\"].min()} to {training_df[\"timestamp\"].max()}')
            logger.info(f'📁 Saved to: {training_file}')
            
        except Exception as e:
            logger.error(f'❌ Dataset preparation failed: {e}')
            sys.exit(1)
        "
        
    - name: Run enhanced feature engineering
      run: |
        python -c "
        import sys
        sys.path.append('.')
        import os
        import pandas as pd
        import shutil
        import logging
        
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        logger.info('🔧 Starting enhanced feature engineering...')
        
        try:
            # Check if training dataset exists
            training_file = 'data_repositories/processed/complete_training_dataset.csv'
            
            if not os.path.exists(training_file):
                logger.error(f'❌ Training dataset not found: {training_file}')
                sys.exit(1)
            
            # Copy training dataset to merged_data.csv for feature engineering compatibility
            merged_file = 'data_repositories/processed/merged_data.csv'
            shutil.copy(training_file, merged_file)
            logger.info(f'📋 Copied training dataset to {merged_file} for feature engineering')
            
            # Initialize enhanced feature engineer
            from phase2_enhanced_feature_engineering import EnhancedFeatureEngineer
            feature_engineer = EnhancedFeatureEngineer()
            
            # Run feature engineering pipeline
            success = feature_engineer.run_pipeline()
            
            if success:
                logger.info('✅ Enhanced feature engineering completed successfully')
                
                # Verify features were created
                features_file = 'data_repositories/features/engineered_features.csv'
                if os.path.exists(features_file):
                    features_df = pd.read_csv(features_file)
                    logger.info(f'📊 Features created: {len(features_df):,} records, {len(features_df.columns)} columns')
                else:
                    logger.warning('⚠️ Features file not found after engineering')
            else:
                logger.error('❌ Feature engineering failed')
                sys.exit(1)
                
        except Exception as e:
            logger.error(f'❌ Feature engineering error: {e}')
            sys.exit(1)
        "
        
    - name: Run Phase 4 CI/CD training pipeline
      run: |
        python -c "
        import sys
        import os
        import logging
        
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        logger.info('🚀 Starting Phase 4 CI/CD training pipeline...')
        
        try:
            # Check if required files exist
            required_files = [
                'phase4_cicd_pipeline_integration.py',
                'phase4_model_development.py',
                'phase4_xgboost_implementation.py',
                'phase4_lightgbm_implementation.py',
                'phase4_final_evaluation.py'
            ]
            
            missing_files = []
            for file in required_files:
                if not os.path.exists(file):
                    missing_files.append(file)
            
            if missing_files:
                logger.error(f'❌ Missing required files: {missing_files}')
                sys.exit(1)
            
            # Run the pipeline
            from phase4_cicd_pipeline_integration import CICDPipelineIntegration
            pipeline = CICDPipelineIntegration()
            success = pipeline.run_complete_pipeline()
            
            if success:
                logger.info('✅ Phase 4 CI/CD pipeline completed successfully')
            else:
                logger.error('❌ Phase 4 CI/CD pipeline failed')
                sys.exit(1)
                
        except Exception as e:
            logger.error(f'❌ Pipeline execution error: {e}')
            import traceback
            logger.error(f'Traceback: {traceback.format_exc()}')
            sys.exit(1)
        "
        
    - name: Validate and promote best model
      run: |
        python -c "
        import os, sys, glob, shutil, logging, json
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        logger.info('🔍 Validating and promoting best model...')
        
        try:
            # Find all production models
            model_candidates = glob.glob('deployment/*/production_model.pkl')
            if not model_candidates:
                logger.error('❌ No production models found. Training pipeline may have failed.')
                sys.exit(1)
            
            # Find the latest model
            latest_model = sorted(model_candidates)[-1]
            logger.info(f'📦 Latest model found: {latest_model}')
            
            # Check for deployment metadata
            deployment_dir = os.path.dirname(latest_model)
            metadata_file = os.path.join(deployment_dir, 'deployment_metadata.json')
            
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                logger.info(f'📊 Model performance: {metadata.get(\"test_r2\", \"N/A\")}')
            
            # Promote to latest
            os.makedirs('deployment', exist_ok=True)
            shutil.copy(latest_model, 'deployment/latest_model.pkl')
            
            # Copy scaler if exists
            scaler_file = os.path.join(deployment_dir, 'production_scaler.pkl')
            if os.path.exists(scaler_file):
                shutil.copy(scaler_file, 'deployment/latest_scaler.pkl')
                logger.info('✅ Latest scaler promoted')
            
            logger.info(f'✅ Model promoted: {latest_model} → deployment/latest_model.pkl')
            
        except Exception as e:
            logger.error(f'❌ Model promotion failed: {e}')
            sys.exit(1)
        "
        
    - name: Validate model performance
      run: |
        python -c "
        import glob, json, logging, sys, os
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        logger.info('📊 Validating model performance...')
        
        try:
            # Check for Phase 4 pipeline reports
            reports = sorted(glob.glob('cicd_pipeline_report_*.json'))
            if not reports:
                logger.error('❌ No pipeline reports found')
                sys.exit(1)
            
            latest_report = reports[-1]
            logger.info(f'📋 Using latest report: {latest_report}')
            
            with open(latest_report, 'r') as f:
                report_data = json.load(f)
            
            # Extract performance metrics
            performance_summary = report_data.get('performance_summary', {})
            best_performance = performance_summary.get('best_performance', 0.0)
            best_model = performance_summary.get('best_model', 'Unknown')
            
            logger.info(f'🏆 Best model: {best_model}')
            logger.info(f'📊 Best test R²: {best_performance:.4f}')
            
            # Realistic performance thresholds for AQI forecasting
            if best_performance >= 0.75:
                logger.info('✅ Excellent performance (≥75% R²)')
            elif best_performance >= 0.65:
                logger.info('✅ Good performance (≥65% R²)')
            elif best_performance >= 0.55:
                logger.warning('⚠️ Acceptable performance (≥55% R²)')
            else:
                logger.warning('⚠️ Performance below threshold (<55% R²)')
            
            # Log additional metrics if available
            if 'model_comparison' in report_data:
                models = report_data['model_comparison']
                logger.info(f'📈 Models trained: {len(models)}')
                for model_name, metrics in models.items():
                    r2 = metrics.get('test_r2', 0.0)
                    logger.info(f'   {model_name}: {r2:.4f} R²')
                    
        except Exception as e:
            logger.error(f'❌ Performance validation failed: {e}')
            sys.exit(1)
        "
        
    - name: Commit model artifacts and reports
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Add model files and reports (force add to override .gitignore)
        git add -f data_repositories/models/ || true
        git add -f deployment/ || true
        git add -f cicd_pipeline_report_*.json || true
        git add -f data_repositories/features/ || true
        
        # Commit with timestamp
        git commit -m "🤖 Model retraining: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" || echo "No changes to commit"
        
        # Pull latest changes before pushing to avoid conflicts
        git pull origin main --rebase || git pull origin main --allow-unrelated-histories
        
        # Push to repository using GITHUB_TOKEN
        git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}
        git push origin main
        
    - name: Create comprehensive training report
      run: |
        echo "# AQI Model Training Report" > model_training_report.md
        echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> model_training_report.md
        echo "**Status:** ✅ Completed" >> model_training_report.md
        echo "" >> model_training_report.md
        echo "## Training Pipeline Summary" >> model_training_report.md
        echo "- **Pipeline:** Phase 4 CI/CD Integration" >> model_training_report.md
        echo "- **Strategy:** Multi-model training with hyperparameter tuning" >> model_training_report.md
        echo "- **Models:** Random Forest, XGBoost, LightGBM + Ensembles" >> model_training_report.md
        echo "- **Data Source:** Historical + Real-time merged (preserved)" >> model_training_report.md
        echo "- **Features:** Enhanced engineering with lag/rolling features" >> model_training_report.md
        echo "" >> model_training_report.md
        echo "## Outputs" >> model_training_report.md
        echo "- **Production Model:** deployment/<timestamp>/production_model.pkl" >> model_training_report.md
        echo "- **Latest Model:** deployment/latest_model.pkl" >> model_training_report.md
        echo "- **Scaler:** deployment/latest_scaler.pkl" >> model_training_report.md
        echo "- **Features:** data_repositories/features/engineered_features.csv" >> model_training_report.md
        echo "- **Reports:** cicd_pipeline_report_*.json" >> model_training_report.md
        echo "" >> model_training_report.md
        echo "## Performance Targets" >> model_training_report.md
        echo "- **Excellent:** ≥75% R²" >> model_training_report.md
        echo "- **Good:** ≥65% R²" >> model_training_report.md
        echo "- **Acceptable:** ≥55% R²" >> model_training_report.md
        echo "- **Below Threshold:** <55% R²" >> model_training_report.md
        
    - name: Upload training report
      uses: actions/upload-artifact@v4
      with:
        name: model-training-report
        path: model_training_report.md
